@misc{hits,
      title={HITS: High-coverage LLM-based Unit Test Generation via Method Slicing}, 
      author={Zejun Wang and Kaibo Liu and Ge Li and Zhi Jin},
      year={2024},
      eprint={2408.11324},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2408.11324}, 
}

@misc{no_more_manual_tests?,
      title={No More Manual Tests? Evaluating and Improving ChatGPT for Unit Test Generation}, 
      author={Zhiqiang Yuan and Yiling Lou and Mingwei Liu and Shiji Ding and Kaixin Wang and Yixuan Chen and Xin Peng},
      year={2024},
      eprint={2305.04207},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2305.04207}, 
}

@misc{the_good_the_bad,
      title={The Good, The Bad, and The Greedy: Evaluation of LLMs Should Not Ignore Non-Determinism}, 
      author={Yifan Song and Guoyin Wang and Sujian Li and Bill Yuchen Lin},
      year={2024},
      eprint={2407.10457},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.10457}, 
}

@misc{llmlingua,
      title={LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models}, 
      author={Huiqiang Jiang and Qianhui Wu and Chin-Yew Lin and Yuqing Yang and Lili Qiu},
      year={2023},
      eprint={2310.05736},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.05736}, 
}

@misc{pan2024llmlingua2datadistillationefficient,
      title={LLMLingua-2: Data Distillation for Efficient and Faithful Task-Agnostic Prompt Compression}, 
      author={Zhuoshi Pan and Qianhui Wu and Huiqiang Jiang and Menglin Xia and Xufang Luo and Jue Zhang and Qingwei Lin and Victor RÃ¼hle and Yuqing Yang and Chin-Yew Lin and H. Vicky Zhao and Lili Qiu and Dongmei Zhang},
      year={2024},
      eprint={2403.12968},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.12968}, 
}

@misc{he2024doespromptformattingimpact,
      title={Does Prompt Formatting Have Any Impact on LLM Performance?}, 
      author={Jia He and Mukund Rungta and David Koleczek and Arshdeep Sekhon and Franklin X Wang and Sadid Hasan},
      year={2024},
      eprint={2411.10541},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2411.10541}, 
}

@misc{cummins2024metalargelanguagemodel,
      title={Meta Large Language Model Compiler: Foundation Models of Compiler Optimization}, 
      author={Chris Cummins and Volker Seeker and Dejan Grubisic and Baptiste Roziere and Jonas Gehring and Gabriel Synnaeve and Hugh Leather},
      year={2024},
      eprint={2407.02524},
      archivePrefix={arXiv},
      primaryClass={cs.PL},
      url={https://arxiv.org/abs/2407.02524}, 
}

@INPROCEEDINGS{a_survey_on_unit_testing_practices_and_problems,
  author={Daka, Ermira and Fraser, Gordon},
  booktitle={2014 IEEE 25th International Symposium on Software Reliability Engineering}, 
  title={A Survey on Unit Testing Practices and Problems}, 
  year={2014},
  volume={},
  number={},
  pages={201-211},
  keywords={Testing;Software;Writing;Java;Reliability;Software engineering;unit testing;test case generation;survey},
  doi={10.1109/ISSRE.2014.11}
}

@inproceedings{testing_the_effect_of_code_documentation,
    title = "Testing the Effect of Code Documentation on Large Language Model Code Understanding",
    author = "Macke, William  and
      Doyle, Michael",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2024",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-naacl.66/",
    doi = "10.18653/v1/2024.findings-naacl.66",
    pages = "1044--1050",
    abstract = "Large Language Models (LLMs) have demonstrated impressive abilities in recent years with regards to code generation and understanding. However, little work has investigated how documentation and other code properties affect an LLM{'}s ability to understand and generate code or documentation. We present an empirical analysis of how underlying properties of code or documentation can affect an LLM{'}s capabilities. We show that providing an LLM with ``incorrect'' documentation can greatly hinder code understanding, while incomplete or missing documentation does not seem to significantly affect an LLM{'}s ability to understand code."
}

@webpage{ai_in_the_development_workflow_interested,
  title        = "{AI in the development workflow - Interested in Using}",
  organization = "Stack Overflow",
  url          = "https://survey.stackoverflow.co/2024/ai#developer-tools-ai-tool-interested",
  refdate      = "2025-06-08"
}

@webpage{ai_tools_next_year,
  title        = "{AI tools next year}",
  organization = "Stack Overflow",
  url          = "https://survey.stackoverflow.co/2024/ai#developer-tools-ai-next",
  refdate      = "2025-06-08"
}

@webpage{agent_leaderboard,
  title        = "{Agent Leaderboard}",
  organization = "Galileo",
  url          = "https://huggingface.co/spaces/galileo-ai/agent-leaderboard",
  refdate      = "2025-06-09"
}
